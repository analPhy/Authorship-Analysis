#generated by Grok
import shutil
import re
import urllib.request
from bs4 import BeautifulSoup
import nltk
from nltk.tokenize import word_tokenize
from IPython.display import display, HTML

# Clear and re-download NLTK data (only if corrupted)
shutil.rmtree('/root/nltk_data', ignore_errors=True)
nltk.download('punkt')
nltk.download('punkt_tab')

# Fetch text from Wikipedia
def get_text_from_url(url):
    response = urllib.request.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')

    for tag in soup(['script', 'style', 'sup', 'table']):
        tag.decompose()

    text = soup.get_text()
    text = re.sub(r'\n+', '\n', text)
    return text

# Clean text
def clean_text(text):
    text = re.sub(r'\[[0-9]+\]', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

# URL for Wikipedia page
URL = 'https://en.wikipedia.org/wiki/Banana'

# Fetch and clean text
raw_text = get_text_from_url(URL)
text = clean_text(raw_text)

# Tokenize text (case-sensitive)
words = word_tokenize(text)

# Prompt user for target phrase (up to two words)
target_input = input("Enter a word or two-word phrase to search (case-sensitive): ").strip()

# Validate input
if not target_input:
    print("Error: No input provided.")
else:
    # Split input into words
    target_words = target_input.split()
    
    if len(target_words) > 2:
        print("Error: Please enter one or two words only.")
    else:
        # Search for target (one or two words)
        found = False
        for i, word in enumerate(words):
            if len(target_words) == 1 and word == target_words[0]:
                found = True
                before = words[max(0, i - 5): i]
                after = words[i + 1: i + 6]
                display(HTML(f"{' '.join(before)} <span style='color:red'>{target_words[0]}</span> {' '.join(after)}"))
            elif len(target_words) == 2 and i < len(words) - 1 and word == target_words[0] and words[i + 1] == target_words[1]:
                found = True
                before = words[max(0, i - 5): i]
                after = words[i + 2: i + 7]  # Adjust to include word after the phrase
                display(HTML(f"{' '.join(before)} <span style='color:red'>{' '.join(target_words)}</span> {' '.join(after)}"))
        
        if not found:
            print(f"Error: The phrase '{' '.join(target_words)}' was not found in the text.")